{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca41d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    " \n",
    "def get_model():\n",
    "    model = torchvision.models.wide_resnet50_2(pretrained=0)\n",
    "    return model\n",
    " \n",
    "def get_onnx(model, onnx_save_path, example_tensor):\n",
    " \n",
    "    example_tensor = example_tensor.cuda()\n",
    "    model = model.cuda()\n",
    " \n",
    "    _ = torch.onnx.export(model,  # model being run\n",
    "                                  example_tensor,  # model input (or a tuple for multiple inputs)\n",
    "                                  onnx_save_path,\n",
    "                                  verbose=False,  # store the trained parameter weights inside the model file\n",
    "                                  do_constant_folding=True,\n",
    "                                  input_names=['input'],\n",
    "                                  output_names=['output']\n",
    "                                  )\n",
    "\n",
    "if __name__ == '__main__':\n",
    " \n",
    "    model = get_model()\n",
    "    onnx_save_path = \"onnx/resnet50_2.onnx\"\n",
    "    example_tensor = torch.randn(1, 3, 288, 512, device='cuda')\n",
    " \n",
    "         # Export model\n",
    "    get_onnx(model, onnx_save_path, example_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc2221aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "def ONNX2TRT(args, calib=None):\n",
    "    ''' convert onnx to tensorrt engine, use mode of ['fp32', 'fp16', 'int8']\n",
    "    :return: trt engine\n",
    "    '''\n",
    " \n",
    "    #assert args.mode.lower() in 'fp32'\n",
    " \n",
    "    G_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with trt.Builder(G_LOGGER) as builder, builder.create_network() as network, \\\n",
    "            trt.OnnxParser(network, G_LOGGER) as parser:\n",
    " \n",
    "        builder.max_batch_size = args.batch_size\n",
    "        builder.max_workspace_size = 1 << 30\n",
    "        if args.mode.lower() == 'int8':\n",
    "            assert (builder.platform_has_fast_int8 == True), \"not support int8\"\n",
    "            builder.int8_mode = True\n",
    "            builder.int8_calibrator = calib\n",
    "        elif args.mode.lower() == 'fp16':\n",
    "            assert (builder.platform_has_fast_fp16 == True), \"not support fp16\"\n",
    "            builder.fp16_mode = True\n",
    " \n",
    "        print('Loading ONNX file from path {}...'.format(args.onnx_file_path))\n",
    "        with open(args.onnx_file_path, 'rb') as model:\n",
    "            print('Beginning ONNX file parsing')\n",
    "            parser.parse(model.read())\n",
    "        print('Completed parsing of ONNX file')\n",
    " \n",
    "        print('Building an engine from file {}; this may take a while...'.format(args.onnx_file_path))\n",
    "        engine = builder.build_cuda_engine(network)\n",
    "        print(\"Created engine success! \")\n",
    " \n",
    "        # Save plan file\n",
    "        print('Saving TRT engine file to path {}...'.format(args.engine_file_path))\n",
    "        with open(args.engine_file_path, \"wb\") as f:\n",
    "            f.write(engine.serialize())\n",
    "        print('Engine file has already saved to {}!'.format(args.engine_file_path))\n",
    "        return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9329eb82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-8dfd087091e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a3729f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.compiler.tensorrt.trt_convert' has no attribute 'Logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f78da1b68ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mONNX2TRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"onnx/resnet50_2.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-6e5f3461782d>\u001b[0m in \u001b[0;36mONNX2TRT\u001b[0;34m(args, calib)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#assert args.mode.lower() in 'fp32'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mG_LOGGER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_LOGGER\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOnnxParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_LOGGER\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.compiler.tensorrt.trt_convert' has no attribute 'Logger'"
     ]
    }
   ],
   "source": [
    "aa = ONNX2TRT(\"onnx/resnet50_2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69974efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadEngine2TensorRT(filepath):\n",
    "    G_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "         # Deserialization engine\n",
    "    with open(filepath, \"rb\") as f, trt.Runtime(G_LOGGER) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c221be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine through engine file\n",
    "engine = loadEngine2TensorRT('path_to_engine_file')\n",
    " \n",
    " # Prepare input and output data\n",
    "img = Image.open('XXX.jpg')\n",
    "img = D.transform(img).unsqueeze(0)\n",
    "img = img.numpy()\n",
    "output = np.empty((1, 2), dtype=np.float32)\n",
    " \n",
    " #Create context\n",
    "context = engine.create_execution_context()\n",
    " \n",
    " # Allocate memory \n",
    "d_input = cuda.mem_alloc(1 * img.size * img.dtype.itemsize)\n",
    "d_output = cuda.mem_alloc(1 * output.size * output.dtype.itemsize)\n",
    "bindings = [int(d_input), int(d_output)]\n",
    " \n",
    " # pycuda operation buffer\n",
    "stream = cuda.Stream()\n",
    " \n",
    " # Put the input data into the device\n",
    "cuda.memcpy_htod_async(d_input, img, stream)\n",
    " \n",
    " # Execution model\n",
    "context.execute_async(100, bindings, stream.handle, None)\n",
    " \n",
    " # Take the prediction result from the buffer\n",
    "cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    " # Thread synchronization\n",
    "stream.synchronize()\n",
    " \n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
